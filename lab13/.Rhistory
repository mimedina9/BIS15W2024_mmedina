knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
library("tidyverse")
library("janitor")
library("lubridate") #this will help us manage dates
files <- list.files(path = "data/spiders", pattern = ".csv", full.names = TRUE)
files
spider_list <- lapply(files, read_csv)
spider_list[[3]]
str(spider_list)
names(spider_list[[5]])
names <- list.files(path = "data/spiders", pattern = ".csv")
names
names_list <- strsplit(names, split = " .csv")
names_list
names_vec <- unlist(names_list)
names_vec
names_vec <- unlist(names_list)
names_vec
spider_list[["Butte"]]
names(spider_list) <- names_vec
names(spider_list)
spider_list[["Butte"]]
spiders_all <- bind_rows(spider_list)
spiders_all
table_A <- read_csv("data/table_A.csv")
table_B <- read_csv("data/table_B.csv")
table_A
table_B
inner_exampleDF <- inner_join(table_A, table_B, by="customer_ID")
inner_exampleDF
left_exampleDF <- left_join(table_A, table_B, by="customer_ID")
left_exampleDF
right_exampleDF <- right_join(table_A, table_B, by="customer_ID")
right_exampleDF
full_exampleDF <- full_join(table_A, table_B, by="customer_ID")
full_exampleDF
anti_exampleDF <- anti_join(table_A, table_B, by="customer_ID")
anti_exampleDF
spiders_locs <- read_csv("data/spiders locations/spiders_locations.csv")
spiders_locs <- read_csv("data/spiders locations/spiders_locations.csv")
spiders_locs
spiders_all
spiders_with_locs <-
left_join(spiders_all, spiders_locs, by="Accession")
summary(spiders_with_locs)
spiders_with_locs <-
full_join(spiders_all, spiders_locs, by="Accession")
summary(spiders_with_locs)
spiders_with_locs <-
full_join(spiders_all, spiders_locs, by="Accession")
summary(spiders_with_locs)
class(spiders_with_locs$Date)
glimpse(spiders_with_locs)
day <- today()
day
str(day)
datetime <- now()
datetime
dmy(spiders_with_locs$Date)
dateformat1 <- "20200922"
dateformat2 <- "09-22-2020"
dateformat3 <- "22/09/2020"
dateformat4 <- "09-22-2020 17:00:00"
dateformat5 <- "20200922 170000"
ymd(dataformat1)
ymd(dataformat1$Date)
ymd(dateformat1)
mdy(dateformat2)
dmy(dateformat3)
mdy_hms(dateformat3)
ymd_hms(dateformat4)
#install.packages("ggmap")
library(ggmap)
library(tidyverse)
library(janitor)
register_stadiamaps("e77f55a8-a371-44cd-a7dd-6384b4586d64", write = FALSE)
spiders <- read_csv("data/spiders_with_locs.csv")%>% clean_names()
spiders <- spiders %>% filter(latitude<=42)
spiders <- spiders %>% filter(latitude<=42)
spiders %>%
select(latitude, longitude) %>%
summary()
lat <- c(34.67, 41.80)
long <- c(-124.1, -115.5)
bbox <- make_bbox(long, lat, f = 0.03) #f is the fraction of the bounding box to add to the range
lat <- c(34.67, 41.80)
long <- c(-124.1, -115.5)
bbox <- make_bbox(long, lat, f = 0.03) #f is the fraction of the bounding box to add to the range
map1 <- get_stadiamap(bbox, maptype = "stamen_terrain", zoom=7)
ggmap(map1)
ggmap(map1) +
geom_point(data = spiders, aes(longitude, latitude), size=0.4) +
labs(x= "Longitude", y= "Latitude", title="Spider Locations")
sharks <- read_csv("data/SharkIncidents_1950_2022_220302.csv") %>%
clean_names() %>%
filter(longitude !="NA" & latitude !="NA") %>% # pulling out NA locations
mutate(longitude = as.numeric(longitude)) # converting longitude to numeric
sharks_dups <- sharks %>%
distinct(location, .keep_all = TRUE) # remove duplicate locations, but keep the remaining variables
sharks_dups %>%
select(latitude, longitude) %>%
summary()
lat <- c(34.67, 41.80)
long <- c(-124.1, -115.5)
bbox <- make_bbox(long, lat, f = 0.03)
lat <- c(32.59, 41.56)
long <- c(-124.7, -117.1)
bbox <- make_bbox(long, lat, f = 0.03)
map2 <- get_stadiamap(bbox, maptype = "stamen_terrain", zoom=7)
ggmap(map2)
View(sharks_dups)
ggmap(map1) +
geom_point(data = sharks_dups, aes(longitude, latitude), size=0.4) +
labs(x= "Longitude", y= "Latitude", title="Shark Attack Locations")
spiders %>%
select(latitude, longitude) %>%
summary()
lat <- c(34.67, 41.80)
long <- c(-124.1, -115.5)
bbox <- make_bbox(long, lat, f = 0.03) #f is the fraction of the bounding box to add to the range
map1 <- get_stadiamap(bbox, maptype = "stamen_terrain", zoom=7)
ggmap(map1)
ggmap(map1) +
geom_point(data = spiders, aes(longitude, latitude), size=0.4) +
labs(x= "Longitude", y= "Latitude", title="Spider Locations")
sharks <- read_csv("data/SharkIncidents_1950_2022_220302.csv") %>%
clean_names() %>%
filter(longitude !="NA" & latitude !="NA") %>% # pulling out NA locations
mutate(longitude = as.numeric(longitude)) # converting longitude to numeric
sharks_dups <- sharks %>%
distinct(location, .keep_all = TRUE) # remove duplicate locations, but keep the remaining variables
sharks_dups %>%
select(latitude, longitude) %>%
summary()
sharks_dups %>%
select(latitude, longitude) %>%
summary()
lat2 <- c(32.59, 41.56)
long2 <- c(-124.7, -117.1)
bbox2 <- make_bbox(long, lat, f = 0.03)
map2 <- get_stadiamap(bbox, maptype = "stamen_terrain", zoom=7)
ggmap(map2)
ggmap(map1) +
geom_point(data = sharks_dups, aes(longitude, latitude), size=0.4) +
labs(x= "Longitude", y= "Latitude", title="Shark Attack Locations")
sharks_dups %>%
select(latitude, longitude) %>%
filter(injury_type=="fatal")
sharks_dups %>%
select(latitude, longitude) %>%
filter(injury=="fatal")
sharks_dups %>%
select(mode,latitude, longitude) %>%
filter(injury=="fatal") %>%
summary()
sharks_fatal <- sharks_dups %>%
filter(injury=="fatal")
sharks_fatal %>%
select(latitude, longitude) %>%
summarize()
sharks_fatal %>%
select(latitude, longitude) %>%
summary()
lat3 <- c(32.85, 39.58)
long3 <- c(-123.8, -117.3)
bbox3 <- make_bbox(long, lat, f = 0.03)
map2 <- get_stadiamap(bbox, maptype = "stamen_terrain", zoom=7)
ggmap(map3)
map3 <- get_stadiamap(bbox, maptype = "stamen_terrain", zoom=7)
ggmap(map3)
ggmap(map3) +
geom_point(data = sharks_dups, aes(longitude, latitude), size=0.4) +
labs(x= "Longitude", y= "Latitude", title="Shark Fatalities Coastal California")
ggmap(map1) +
geom_point(data = sharks_dups, aes(longitude, latitude, color="injury"), size=0.4) +
labs(x= "Longitude", y= "Latitude", title="Shark Attack Locations")
